{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9df13e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:59:17.304703Z",
     "start_time": "2021-09-30T01:59:17.272181Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b3a0ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:02.953021Z",
     "start_time": "2021-09-30T01:56:02.818215Z"
    }
   },
   "outputs": [],
   "source": [
    "data_source = COCO(annotation_file='E:/LitterDetection/TACO/data/labels.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba0d07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:03.085944Z",
     "start_time": "2021-09-30T01:56:03.073990Z"
    }
   },
   "outputs": [],
   "source": [
    "#test labels\n",
    "#label_transfer = {5: 0, 12: 1, 6: 2, 22: 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bedaca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:03.256421Z",
     "start_time": "2021-09-30T01:56:03.252229Z"
    }
   },
   "outputs": [],
   "source": [
    "#create all labels\n",
    "gen = ((i, i-1) for i in range(1, 61))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f6a184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:03.688310Z",
     "start_time": "2021-09-30T01:56:03.684348Z"
    }
   },
   "outputs": [],
   "source": [
    "label_transfer = dict(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24132d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:04.080426Z",
     "start_time": "2021-09-30T01:56:04.068770Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a2ee2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:06.832253Z",
     "start_time": "2021-09-30T01:56:06.816292Z"
    }
   },
   "outputs": [],
   "source": [
    "img_ids = data_source.getImgIds()\n",
    "catIds = data_source.getCatIds()\n",
    "categories = data_source.loadCats(catIds)\n",
    "\n",
    "categories.sort(key=lambda x: x['id'])\n",
    "\n",
    "classes = {}\n",
    "coco_labels = {}\n",
    "coco_labels_inverse = {}\n",
    "for c in categories:\n",
    "    coco_labels[len(classes)] = c['id']\n",
    "    coco_labels_inverse[c['id']] = len(classes)\n",
    "    classes[c['name']] = len(classes)\n",
    "\n",
    "class_num = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc05f6e",
   "metadata": {},
   "source": [
    "## Collect images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa4c37b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:07.905261Z",
     "start_time": "2021-09-30T01:56:07.885242Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a parent Directory path (were to store everything)\n",
    "parent_dir = \"E:/LitterDetection/TACO/\"\n",
    "directory1 = \"tmp/images/\" \n",
    "directory2 = \"tmp/labels/\"\n",
    "path1 = os.path.join(parent_dir, directory1)\n",
    "path2 = os.path.join(parent_dir, directory2)\n",
    "os.makedirs(path1, exist_ok = True)\n",
    "os.makedirs(path2, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbd186e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:08.402972Z",
     "start_time": "2021-09-30T01:56:08.398983Z"
    }
   },
   "outputs": [],
   "source": [
    "save_base_path  = 'tmp/labels/'\n",
    "save_image_path = 'tmp/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d6e3a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:08.953881Z",
     "start_time": "2021-09-30T01:56:08.936092Z"
    }
   },
   "outputs": [],
   "source": [
    "data_source.loadImgs(img_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f51877d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:09.519014Z",
     "start_time": "2021-09-30T01:56:09.511017Z"
    }
   },
   "outputs": [],
   "source": [
    "a = data_source.getAnnIds(img_ids[0])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fb0a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:10.016641Z",
     "start_time": "2021-09-30T01:56:09.998288Z"
    }
   },
   "outputs": [],
   "source": [
    "data_source.loadAnns(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0ee2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:56:10.630153Z",
     "start_time": "2021-09-30T01:56:10.618493Z"
    }
   },
   "outputs": [],
   "source": [
    "boxes = np.zeros((0, 5))\n",
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b37a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:57:01.426759Z",
     "start_time": "2021-09-30T01:56:11.560745Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, img_id in tqdm.tqdm(enumerate(img_ids), desc='change .json file to .txt file'):\n",
    "    img_info = data_source.loadImgs(img_id)[0] #we need a 0 so we access the dictionary. without it, it would give a dictionary inside a list\n",
    "    # Modify the path containing the folder to the file name\n",
    "    save_name = img_info['file_name'].replace('/', '_')\n",
    "    # Remove file extension\n",
    "    file_name = save_name.split('.')[0]\n",
    "    # Get the width and height of a single image\n",
    "    height = img_info['height']\n",
    "    width = img_info['width']\n",
    "    # The storage path of the converted txt file\n",
    "    save_path = save_base_path + file_name + '.txt'\n",
    "    is_exist = False  \n",
    "    # Record whether the picture contains the target garbage type object\n",
    "    with open(save_path, mode='w') as fp:\n",
    "        # Find out the number set of garbage objects according to the picture number\n",
    "        annotation_id = data_source.getAnnIds(img_id)\n",
    "        print('annotation:', annotation_id)\n",
    "        boxes = np.zeros((0, 5))\n",
    "        if len(annotation_id) == 0:  # Collection size is 0\n",
    "            fp.write('')\n",
    "            continue\n",
    "        # Get tags from coco format\n",
    "        annotations = data_source.loadAnns(annotation_id)\n",
    "        lines = ''  \n",
    "        \n",
    "        #Record the label into yolo format after conversion\n",
    "        \n",
    "        # Traverse the annotations dictionary\n",
    "        for annotation in annotations:\n",
    "            # Get the label of the garbage object\n",
    "            label = coco_labels_inverse[annotation['category_id']]\n",
    "            print('label:', label)\n",
    "            if label in label_transfer.keys(): #look into all the labels from the dataset \n",
    "                # If the garbage type belongs to the target garbage type, the format conversion is performed\n",
    "                is_exist = True\n",
    "                box = annotation['bbox']\n",
    "                if box[2] < 1 or box[3] < 1:#include all images (this is just to make sure that everything is included)\n",
    "                    # Skip if there is no length or width data in the original label\n",
    "                    continue\n",
    "                # top_x, top_y, width, height ==> cen_x, cen_y, width, height\n",
    "                box[0] = round((box[0] + box[2] / 2) / width, 6) #divide by width since it is the x axis\n",
    "                box[1] = round((box[1] + box[3] / 2) / height, 6)\n",
    "                box[2] = round(box[2] / width, 6)\n",
    "                box[3] = round(box[3] / height, 6)\n",
    "                                            \n",
    "                label = label_transfer[label]  # Label mapping for the current label number\n",
    "                if label not in class_num.keys():\n",
    "                    class_num[label] = 0\n",
    "                class_num[label] = class_num.values()\n",
    "                lines = lines + str(label)  # Store tags first\n",
    "                for i in box:  # Restore location information\n",
    "                    lines += ' ' + str(i)\n",
    "                lines += '\\n'  # Line up\n",
    "                print('label:', label)\n",
    "                \n",
    "        fp.writelines(lines) #write all this new information\n",
    "    if is_exist:\n",
    "        # If there is an object of the target type, copy the image to the specified directory\n",
    "        shutil.copy('E:/LitterDetection/TACO/data/{}'.format(img_info['file_name']), os.path.join(save_image_path, save_name))\n",
    "    else:\n",
    "        # If it does not exist, delete the generated label file\n",
    "        os.remove(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab056e1",
   "metadata": {},
   "source": [
    "## Split folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a5fcad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T01:59:47.935300Z",
     "start_time": "2021-09-30T01:59:22.418900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2972 files [00:25, 116.63 files/s]\n"
     ]
    }
   ],
   "source": [
    "#to split into train, validation and test\n",
    "import splitfolders\n",
    "splitfolders.ratio('tmp', output=\"taco\", seed=1337, ratio=(.8, 0.1,0.1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd41e3e",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-startup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tf-latest)",
   "language": "python",
   "name": "tf-latest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
